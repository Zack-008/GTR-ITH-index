{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clinical = pd.read_excel('/path/to/clinical_data')\n",
    "\n",
    "df_train_radiomics_standardized = pd.read_excel('/path/to/scaled_train_set')\n",
    "scaled_features_val = pd.read_excel('/path/to/scaled_inval_set')\n",
    "scaled_test_set = pd.read_excel('/path/to/scaled_test_set')\n",
    "scaled_TCIA_TCGA = pd.read_excel('/path/to/scaled_TCIA_TCGA')\n",
    "\n",
    "#The same standardization applied to the training set has already been applied to the other datasets.\n",
    "\n",
    "df_clinical_final = df_clinical.rename(columns={'ORR_RECIST1.1': 'ORR'})\n",
    "df_train_set = pd.merge(df_train_radiomics_standardized, df_clinical_final[[ 'ORR']], on='ID', how='left')\n",
    "df_inval_set= pd.merge(scaled_features_val, df_clinical_final[[ 'ORR']], on='ID', how='left' )\n",
    "external_test_set= pd.merge(scaled_test_set, df_clinical_final[[ 'ORR']], on='ID', how='left' )\n",
    "\n",
    "df_clinical_TCIA_set = pd.read_excel('/path/to/df_TCGA_clinical_data')\n",
    "TCGA_TCIA_set= pd.merge(scaled_TCIA_TCGA, df_clinical_TCIA_set, on='case_submitter_id', how='left' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes_list = pd.read_excel('/path/to/final_features_GTR_list')\n",
    "prefixes_to_keep = prefixes_list['Feature'].tolist()\n",
    "\n",
    "X_df_train= df_train_set[prefixes_to_keep]\n",
    "y_df_train = df_train_set['ORR']\n",
    "\n",
    "X_val_K = df_inval_set[prefixes_to_keep]\n",
    "y_val = df_inval_set['ORR']\n",
    "\n",
    "X_external = external_test_set[prefixes_to_keep]\n",
    "Y_external = external_test_set['ORR']\n",
    "\n",
    "X_TCGA_TCIA_set = TCGA_TCIA_set[prefixes_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######  Random Forest  ######\n",
    "rf = RandomForestClassifier()\n",
    "n_estimators_range=[50, 100, 200, 300]\n",
    "max_depth_range=[10,50,100,150,200,300,500]\n",
    "max_depth_range.append(None)\n",
    "min_samples_split_range= list(range(2, 11, 1))\n",
    "min_samples_leaf_range=list(range(1, 11, 1))\n",
    "\n",
    "param_grid_rf={\n",
    "    'n_estimators':n_estimators_range,\n",
    "    'max_depth':max_depth_range,\n",
    "    'min_samples_split':min_samples_split_range,\n",
    "    'min_samples_leaf':min_samples_leaf_range\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(estimator=rf, param_grid=param_grid_rf, cv=10, n_jobs=-1, verbose=2)\n",
    "\n",
    "grid_search_rf.fit(X_df_train, y_df_train)\n",
    "\n",
    "print('Best parameters for Random Forest: ', grid_search_rf.best_params_)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######  Decision Tree  ######\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "max_depth_range = list(range(1,21,1))\n",
    "min_samples_leaf_range = list(range(2,21,1))\n",
    "min_samples_split= list(range(2,21,1))\n",
    "\n",
    "param_grid_dt = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': max_depth_range,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_samples_leaf': min_samples_leaf_range,\n",
    "}\n",
    "\n",
    "grid_search_dt = GridSearchCV(estimator=dt, param_grid=param_grid_dt, cv=10, n_jobs=-1, verbose=2)\n",
    "\n",
    "grid_search_dt.fit(X_df_train, y_df_train)\n",
    "\n",
    "print('Best parameters for Decision Tree: ', grid_search_dt.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######  Support Vector Machine  ######\n",
    "svm = SVC(probability=True)  \n",
    "\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1,2,3,10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto',  0.001,0.01,0.1, 0.2, 1],\n",
    "    'max_iter':[1000000]\n",
    "}\n",
    "\n",
    "grid_search_svm = GridSearchCV(estimator=svm, param_grid=param_grid_svm, cv=10, n_jobs=-1, verbose=2)\n",
    "\n",
    "grid_search_svm.fit(X_df_train, y_df_train)\n",
    "\n",
    "print('Best parameters for SVM: ', grid_search_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######  Logistic Regression  ######\n",
    "lr = LogisticRegression()\n",
    "grid_search_lr = LogisticRegression()\n",
    "grid_search_lr.fit(X_df_train, y_df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######  XGBoost  ######\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "n_estimators_range = [50,100,150,200,300,500] \n",
    "max_depth_range=list(range(3,11,1))\n",
    "min_child_weight_range=list(range(1,11,1))\n",
    "\n",
    "subsample_range= [0.5, 0.7, 0.9,1.0]\n",
    "learning_rate_range= [0.01,0.02, 0.1, 0.15 ,0.2]\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': n_estimators_range,\n",
    "    'max_depth': max_depth_range,\n",
    "    'learning_rate': learning_rate_range,\n",
    "    'subsample': subsample_range,\n",
    "    'min_child_weight': min_child_weight_range\n",
    "}\n",
    "\n",
    "grid_search_xgb = GridSearchCV(estimator=xgb, param_grid=param_grid_xgb, cv=10, n_jobs=-1, verbose=2)\n",
    "\n",
    "grid_search_xgb.fit(X_df_train, y_df_train)\n",
    "\n",
    "print('Best parameters for XGBoost: ', grid_search_xgb.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the optimal model\n",
    "opt_rf = RandomForestClassifier(**grid_search_rf.best_params_)\n",
    "opt_svm = SVC(**grid_search_svm.best_params_, probability=True)\n",
    "opt_lr = LogisticRegression()  \n",
    "opt_dt = DecisionTreeClassifier(**grid_search_dt.best_params_)\n",
    "opt_xgb = XGBClassifier(**grid_search_xgb.best_params_)\n",
    "\n",
    "\n",
    "# Define the stacking model\n",
    "stack = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', opt_rf),\n",
    "        ('svm', opt_svm),\n",
    "        ('lr', opt_lr),\n",
    "        ('dt', opt_dt),\n",
    "        ('xgb', opt_xgb)\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(),\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# Train the stacking model\n",
    "stack.fit(X_df_train, y_df_train)\n",
    "\n",
    "# Validate the model performance\n",
    "stack_score_tra = stack.score(X_df_train, y_df_train)\n",
    "stack_score_val = stack.score(X_val_K, y_val)\n",
    "stack_score_ext = stack.score(X_external, Y_external)\n",
    "\n",
    "print(f'Accuracy of stacked model in trainning: {stack_score_tra:.2f}')\n",
    "print(f'Accuracy of stacked model in validation: {stack_score_val:.2f}')\n",
    "print(f'Accuracy of stacked model in testing: {stack_score_ext:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predicted probabilities\n",
    "probs_train = stack.predict_proba(X_df_train)[:, 1]\n",
    "probs_internal_test = stack.predict_proba(X_val_K)[:, 1]\n",
    "probs_external_test = stack.predict_proba(X_external)[:, 1]\n",
    "probs_TCGA_TCIA_set = stack.predict_proba(X_TCGA_TCIA_set)[:, 1]\n",
    "\n",
    "pred_train = stack.predict(X_df_train)\n",
    "pred_internal_test = stack.predict(X_val_K)\n",
    "pred_external_test = stack.predict(X_external)\n",
    "pred_TCGA_TCIA_set = stack.predict(X_TCGA_TCIA_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
