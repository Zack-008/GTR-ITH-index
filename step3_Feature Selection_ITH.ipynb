{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pingouin as pg\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from mirp import extract_features\n",
    "from mirp.settings.perturbation_parameters import ImagePerturbationSettingsClass\n",
    "from sklearn.mixture import GaussianMixture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perturbation  (GTR & ITH Level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path='/path/to/your/data'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_label(row):\n",
    "    if row['image_noise_level'] == 0 and pd.isna(row['image_noise_iteration_id']) and row['image_rotation_angle'] == 0 and row['image_translation_x'] == 0 and row['image_translation_y'] == 0 and row['image_translation_z'] == 0:\n",
    "        return 'r1'\n",
    "    elif row['image_noise_iteration_id'] == 0 and row['image_rotation_angle'] == 0.5 and row['image_translation_x'] == 0.5 and row['image_translation_y'] == 0.5 and row['image_translation_z'] == 0.5:\n",
    "        return 'r2'\n",
    "    elif row['image_noise_iteration_id'] == 1 and row['image_rotation_angle'] == 0.5 and row['image_translation_x'] == 0.5 and row['image_translation_y'] == 0.5 and row['image_translation_z'] == 0.5:\n",
    "        return 'r3'\n",
    "    else:\n",
    "        return 'other' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dataset(list_volume, list_mask=None):\n",
    "\n",
    "    if list_mask is None:  \n",
    "        lists_to_check = [list_volume]\n",
    "    else: \n",
    "        if len(list_volume) != len(list_mask):\n",
    "            raise ValueError('There exists a mismatch between two datasets.')\n",
    "        lists_to_check = [list_volume, list_mask]\n",
    "    \n",
    "    errors_df = pd.DataFrame(columns=['File_Path', 'Type'])\n",
    "    \n",
    "    for list_index, file_list in enumerate(lists_to_check):\n",
    "        list_type = 'Volume' if list_index == 0 else 'Mask'\n",
    "        for file_path in file_list:\n",
    "            if not os.path.exists(file_path):\n",
    "                \n",
    "                temp_df = pd.DataFrame({'File_Path': [file_path], 'Type': [list_type]})\n",
    "                errors_df = pd.concat([errors_df, temp_df], ignore_index=True)\n",
    "    \n",
    "    if not errors_df.empty:\n",
    "        errors_df.to_excel('/path/to/errors_file_paths', index=False)\n",
    "        print('Invalid file paths were found and have been saved to “errors_file_paths”.')\n",
    "    else:\n",
    "        print('All file paths exist.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_filtered_files = glob.glob(os.path.join(source_path,'perturbation','Label_ITH', '*'))\n",
    "\n",
    "image_files = []\n",
    "for file_path in mask_filtered_files:\n",
    "    new_filename =os.path.join(source_path,'ICC_calculate','Image_ITH','_'.join(os.path.basename(file_path).split('_')[3:-2])+ '_image_'+os.path.basename(file_path).split('_')[-1])\n",
    "    image_files.append(new_filename)\n",
    "\n",
    "check_dataset(image_files, mask_filtered_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(image_batch, mask_batch, settings, output_file, append=False):\n",
    "    feature_data = extract_features(\n",
    "        image=image_batch,\n",
    "        mask=mask_batch,\n",
    "        base_discretisation_method='fixed_bin_number',\n",
    "        image_modality='CT',\n",
    "        base_discretisation_bin_width=16.0,\n",
    "        settings=settings\n",
    "    )\n",
    "    combined_df = pd.concat(feature_data, ignore_index=True)\n",
    "    \n",
    "    write_mode = 'a' if append else 'w'\n",
    "    header = not append \n",
    "    combined_df.to_csv(output_file, mode=write_mode, header=header, index=False)\n",
    "\n",
    "\n",
    "settings = os.path.join(source_path,'perturbation','perturbation_test_config_settings.xml')\n",
    "output_file = os.path.join(source_path,'perturbation','Perturbation_featurelevel_output.csv')\n",
    "\n",
    "batch_size = 10  \n",
    "num_batches = len(image_files) // batch_size + (1 if len(image_files) % batch_size > 0 else 0)\n",
    "\n",
    "for i in range(num_batches):\n",
    "    start_idx = i * batch_size\n",
    "    end_idx = start_idx + batch_size\n",
    "    image_batch = image_files[start_idx:end_idx]\n",
    "    mask_batch = mask_filtered_files[start_idx:end_idx]\n",
    "    process_batch(image_batch, mask_batch, settings, output_file, append=i > 0)\n",
    "print('Finish for all batches.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Perturbation_featurelevel = pd.read_csv(os.path.join(source_path,'ICC_calculate','Perturbation_featurelevel_output.csv'))\n",
    "\n",
    "Perturbation_featurelevel['reader'] = Perturbation_featurelevel.apply(assign_label, axis=1)\n",
    "Perturbation_featurelevel_cleaned = Perturbation_featurelevel.dropna(subset=['cm_joint_var_d1_3d_v_mrg_fbs_w16.0', 'ngl_ldlge_d1_a0.0_3d_fbs_w16.0'])\n",
    "\n",
    "prefixes_to_keep = ['stat_', 'ivh_', 'morph_', 'ih_', 'cm_', 'rlm_','szm_', 'dzm_','ngt_','ngl_']\n",
    "columns_to_keep = ['sample_name','reader'] + [col for col in Perturbation_featurelevel.columns if any(col.startswith(prefix) for prefix in prefixes_to_keep)]\n",
    "\n",
    "ICC_Pert = Perturbation_featurelevel[columns_to_keep].copy() \n",
    "\n",
    "ICC_Pert['sample_name'] = ICC_Pert['sample_name'].astype(str)\n",
    "ICC_Pert['reader'] = ICC_Pert['reader'].astype(str)\n",
    "\n",
    "icc_Pert_results =  []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for column in ICC_Pert.columns[2:]:\n",
    "    icc_data = ICC_Pert[['sample_name', 'reader', column]].copy()\n",
    "    icc_data = icc_data.pivot(index='sample_name', columns='reader', values=column).reset_index()\n",
    "    icc_data.columns.name = None  \n",
    "    \n",
    "    icc_data_melted = icc_data.melt(id_vars='sample_name', value_vars=['r1', 'r2', 'r3'], var_name='reader', value_name=column)\n",
    "    icc = pg.intraclass_corr(data=icc_data_melted, targets='sample_name', raters='reader', ratings=column, nan_policy='omit').round(3)\n",
    "    icc['feature'] = column  \n",
    "    icc_Pert_results.append(icc)\n",
    "\n",
    "per_results_df = pd.concat(icc_Pert_results, ignore_index=True)\n",
    "per_results_df.to_csv('/path/to/perturbation_result_featurelevel.csv')\n",
    "print('ICC calculation complete!')\n",
    "\n",
    "per_filtered_df = per_results_df[(per_results_df['Type'] == 'ICC3k') & (per_results_df['ICC'] <= 0.75)] \n",
    "per_features_remove = per_filtered_df['feature'].unique()\n",
    "len(per_features_remove)\n",
    "\n",
    "# These features need to align with corresponding pyradiomics features.\n",
    "mapping = ('/path/to/feature_correspond')\n",
    "mapping = mapping.dropna()\n",
    "mapping_dict = pd.Series(mapping.new_name.values, index=mapping.sample_name).to_dict()\n",
    "replaced_features = []\n",
    "for feature in per_features_remove:\n",
    "\n",
    "    if pd.isna(feature):\n",
    "        replaced_features.append(feature)\n",
    "        continue\n",
    "    \n",
    "    replaced = False\n",
    "    for partial_name in mapping_dict.keys():\n",
    "        if partial_name in feature:\n",
    "            replaced_features.append(mapping_dict[partial_name])\n",
    "            replaced = True\n",
    "            break\n",
    "    if not replaced:\n",
    "        replaced_features.append(feature)\n",
    "\n",
    "replaced_features = np.array(replaced_features)\n",
    "print(replaced_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_removed_features_ITH = np.unique(replaced_features)  \n",
    "len(combined_removed_features_ITH) \n",
    "\n",
    "final_combined_removed_features_ITH = pd.DataFrame(combined_removed_features_ITH, columns=['removed_Feature'])\n",
    "final_combined_removed_features_ITH.to_excel('/path/to/Removed_features_ITH', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Dimensionality Reduction--ITH Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "return the K value and covariance_type from the best GMM model according to the BIC\n",
    "'''\n",
    "def get_K(feature, K_num):    \n",
    "    lowest_bic = np.infty   \n",
    "    bic = []                 \n",
    "    n_components_range = range(1, K_num+1)     \n",
    "    cv_types = ['full']  \n",
    "\n",
    "    for cv_type in cv_types:      \n",
    "        for n_components in n_components_range:\n",
    "            gmm = GaussianMixture(\n",
    "                n_components=n_components, covariance_type=cv_type,random_state=0\n",
    "            )\n",
    "            gmm.fit(feature)\n",
    "            bic.append(gmm.bic(feature))    \n",
    "            if bic[-1] < lowest_bic:\n",
    "                lowest_bic = bic[-1]\n",
    "                best_gmm = gmm\n",
    "\n",
    "    bic = np.array(bic)         \n",
    "    return best_gmm.n_components, best_gmm.covariance_type       \n",
    "\n",
    "'''\n",
    "For each feature, assign a K value based on GMM(BIC)\n",
    "Assume each patient has N features, return a list with shape (1,N) which include K for each feature\n",
    "'''\n",
    "def assign_K_value2features(Patient_features, K_num):   \n",
    "    x, y = Patient_features.shape        \n",
    "    K_list = []                  \n",
    "    cov_type_list = []\n",
    "    for feature_idx in range(0, y):       \n",
    "        X_train = np.array(Patient_features.iloc[:, feature_idx]).reshape(-1,1)\n",
    "        k, cov_type = get_K(X_train, K_num)\n",
    "        K_list.append(k)\n",
    "        cov_type_list.append(cov_type)\n",
    "\n",
    "    return K_list, cov_type_list   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_patient_features(Patient_features, K_list, cov_type_list):\n",
    "    cluster_labels_dict = {} \n",
    "    for feature_idx, (k, cov_type) in enumerate(zip(K_list, cov_type_list)):\n",
    "        feature_name = Patient_features.columns[feature_idx]  \n",
    "        X_train = np.array(Patient_features.iloc[:, feature_idx]).reshape(-1, 1)\n",
    "        gmm = GaussianMixture(n_components=k, covariance_type=cov_type, random_state=0)  \n",
    "        gmm.fit(X_train)  \n",
    "        labels = gmm.predict(X_train) \n",
    "        cluster_labels_dict[feature_name + '_Cluster'] = labels \n",
    "\n",
    "    cluster_labels_df = pd.DataFrame(cluster_labels_dict)\n",
    "    \n",
    "    return cluster_labels_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_features(df_stand, id_columns):\n",
    "    if isinstance(id_columns, str): \n",
    "        id_columns = [id_columns]\n",
    "\n",
    "    df_stand.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    features_to_scale = df_stand.drop(columns=id_columns)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(features_to_scale)\n",
    "    \n",
    "    scaled_features_df = pd.DataFrame(scaled_features, columns=features_to_scale.columns)\n",
    "    \n",
    "    id_columns_df = df_stand[id_columns]\n",
    "    \n",
    "    result_df = pd.concat([id_columns_df, scaled_features_df], axis=1)\n",
    "    \n",
    "    return result_df, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clinical = pd.read_excel('/path/to/clinical_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intratumor Feature ITH Level Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_pyradiomics_ITH = pd.read_excel('/path/to/Training_feature_ITH')\n",
    "\n",
    "prefixes_features_featurelevel_remove = final_combined_removed_features_ITH['removed_Feature'].tolist() \n",
    "training_pyradiomics_cluster_ITH= training_pyradiomics_ITH.drop(columns=prefixes_features_featurelevel_remove) \n",
    "\n",
    "columns_to_drop = training_pyradiomics_cluster_ITH.filter(like='original_shape').columns  \n",
    "training_pyradiomics_cluster_ITH=training_pyradiomics_cluster_ITH.drop(columns=columns_to_drop)\n",
    "\n",
    "training_inval_set = training_pyradiomics_cluster_ITH.drop(['ID','CaseID'], axis=1).apply(pd.to_numeric).reset_index(drop=True)\n",
    "\n",
    "train_set, training_scaler = standardize_features(training_inval_set, ['ID','CaseID'])\n",
    "train_set= train_set.drop(columns='CaseID') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Patients_K = pd.DataFrame()\n",
    "cluster_labels_all = pd.DataFrame()\n",
    "ptid = []\n",
    "Patients_covtype = []\n",
    "ptid_K0 = []\n",
    "\n",
    "K_num = 5\n",
    "\n",
    "for ptid, group in train_set.groupby('CaseID'):       \n",
    "    \n",
    "    try:\n",
    "        analysis_data = group.drop(['CaseID'], axis=1)\n",
    "        K, cov_type_list = assign_K_value2features(analysis_data.drop(['ID'], axis=1), K_num)  \n",
    "        if sum(K) != 0:\n",
    "            cluster_labels_df = cluster_patient_features(analysis_data.drop(['ID'], axis=1), K, cov_type_list)\n",
    "\n",
    "            cluster_labels_df['ID'] = analysis_data['ID'].values  \n",
    "            cluster_labels_df['CaseID'] = ptid\n",
    "\n",
    "            cols = cluster_labels_df.columns.tolist()\n",
    "            cols = ['ID', 'CaseID'] + [col for col in cols if col not in ['ID', 'CaseID']]\n",
    "            cluster_labels_df = cluster_labels_df[cols]\n",
    "            cluster_labels_all = pd.concat([cluster_labels_all, cluster_labels_df], ignore_index=True, axis=0)\n",
    "\n",
    "            K_new = [ptid] + K  \n",
    "            K_new_df=pd.DataFrame([K_new], columns=['CaseID'] +  list(train_set.columns.drop(['ID','CaseID'])))\n",
    "            Patients_K = pd.concat([Patients_K, K_new_df], ignore_index=True, axis=0)\n",
    "            # print(f'{ptid} is done')\n",
    "        else:\n",
    "            ptid_K0.append(ptid)\n",
    "            print(f'something wrong: K is 0 for patient {ptid}')\n",
    "    except Exception as e:\n",
    "        print(f'Error: something wrong about K for patient {ptid}, Error: {e}')\n",
    "    finally:\n",
    "        Patients_covtype.append((ptid, cov_type_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Patients_K_IDrep = pd.merge(training_pyradiomics_ITH[['CaseID']], Patients_K, on='CaseID', how='left')\n",
    "Patients_K_IDrep.to_excel('/path/to/training_ITH_feature_vector')\n",
    "#cluster_labels_all.to_excel('/path/to/training_ITH_feature_cluster')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson correlation analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pearson Correlation Coefficient (PCC) to remove highly correlated features\n",
    "corr_matrix = Patients_K.drop(['CaseID'], axis=1).corr()  \n",
    "\n",
    "high_corr_var=np.where(corr_matrix>0.75)  \n",
    "\n",
    "to_remove = set()  \n",
    "\n",
    "for var in zip(*high_corr_var):  \n",
    "    if var[0] != var[1] and var[0] not in to_remove: \n",
    "        to_remove.add(var[1]) \n",
    "\n",
    "df_filtered = Patients_K.drop(columns=Patients_K.columns[list(to_remove)]) \n",
    "pcc_features_remove = corr_matrix.columns[list(to_remove)]\n",
    "len(pcc_features_remove)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Independent T-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = pd.merge(df_filtered, training_pyradiomics_ITH[['CaseID']], on='CaseID', how='left')\n",
    "df_Ttest = pd.merge(df_filtered, df_clinical[['CaseID', 'ORR_RECIST1.1']], on='CaseID', how='left')\n",
    "\n",
    "columns = list(df_Ttest.columns)\n",
    "columns.remove('ORR_RECIST1.1')\n",
    "columns.insert(1, 'ORR_RECIST1.1')\n",
    "df_Ttest = df_Ttest[columns] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_0 = df_Ttest[df_Ttest['ORR_RECIST1.1'] == 0]  \n",
    "group_1 = df_Ttest[df_Ttest['ORR_RECIST1.1'] == 1] \n",
    "\n",
    "features = df_Ttest.columns[2:]\n",
    "\n",
    "significant_features = []\n",
    "p_values = []\n",
    "for feature in features:\n",
    "    stat, p_value = ttest_ind(group_0[feature], group_1[feature])\n",
    "    p_values.append(p_value)  \n",
    "    if p_value < 0.05: \n",
    "        significant_features.append(feature)\n",
    "\n",
    "print(len(significant_features), 'Significant features:', significant_features)\n",
    "\n",
    "p_values_df = pd.DataFrame({'Feature': features, 'P-Value': p_values})\n",
    "print(p_values_df)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features_patientlevel = pd.DataFrame(significant_features, columns=['Feature'])\n",
    "final_features_patientlevel.to_excel('/path/to/final_features_ITH_list')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internal validation set cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inval_set_pyradiomics_ITH = pd.read_excel('/path/to/Inval_feature_ITH')\n",
    "columns_to_keep = ['CaseID','ID'] + [col for col in inval_set_pyradiomics_ITH.columns if col in significant_features]\n",
    "\n",
    "inval_pyradiomics_ITH = inval_set_pyradiomics_ITH[columns_to_keep].copy()  \n",
    "\n",
    "df_numeric_inval = inval_pyradiomics_ITH.drop(['ID','CaseID'], axis=1).apply(pd.to_numeric)\n",
    "inval_pyradiomics_cluster_test_ITH = df_numeric_inval.reset_index(drop=True)\n",
    "\n",
    "features_to_scale_validation_ITH = inval_pyradiomics_cluster_test_ITH.drop(['CaseID','ID'], axis=1)\n",
    "scaled_features_validation_ITH  = training_scaler.transform(features_to_scale_validation_ITH)\n",
    "\n",
    "scaled_features_validation_df = pd.DataFrame(scaled_features_validation_ITH, columns=features_to_scale_validation_ITH.columns)\n",
    "df_validation_standardized = pd.concat([inval_pyradiomics_cluster_test_ITH[['CaseID', 'ID']], scaled_features_validation_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Patients_K_exter=  Patients_K[['CaseID'] +[col for col in Patients_K.columns if col in significant_features]].copy()\n",
    "max_K_values = Patients_K_exter.iloc[:, 1:].max()\n",
    "\n",
    "cluster_labels_validation_all = df_validation_standardized\n",
    "ptid_K0_test = []\n",
    "Patients_K_test = pd.DataFrame()\n",
    "cluster_labels_all_test = pd.DataFrame()\n",
    "ptid = []\n",
    "Patients_covtype_test = []\n",
    "\n",
    "\n",
    "for ptid, group in cluster_labels_validation_all.groupby('CaseID'):\n",
    "    try:\n",
    "        analysis_data = group.drop(['CaseID'], axis=1)\n",
    "        K, cov_type_list = assign_K_value2features(analysis_data.drop(['ID'], axis=1), K_num) \n",
    "        K_limited = K\n",
    "\n",
    "        if sum(K_limited) != 0:\n",
    "            cluster_labels_df = cluster_patient_features(analysis_data.drop(['ID'], axis=1), K_limited, cov_type_list)\n",
    "\n",
    "            cluster_labels_df['ID'] = analysis_data['ID'].values \n",
    "            cluster_labels_df['CaseID'] = ptid\n",
    "\n",
    "            cols = cluster_labels_df.columns.tolist()\n",
    "            cols = ['ID', 'CaseID'] + [col for col in cols if col not in ['ID', 'CaseID']]\n",
    "            cluster_labels_df = cluster_labels_df[cols]\n",
    "            cluster_labels_all_test = pd.concat([cluster_labels_all_test, cluster_labels_df], ignore_index=True, axis=0)\n",
    "\n",
    "            K_new = [ptid] + K_limited  \n",
    "            K_new_df=pd.DataFrame([K_new], columns=['CaseID'] +  list(cluster_labels_validation_all.columns.drop(['ID','CaseID'])))\n",
    "            Patients_K_test = pd.concat([Patients_K_test, K_new_df], ignore_index=True, axis=0)\n",
    "        else:\n",
    "            ptid_K0_test.append(ptid)\n",
    "            print(f'something wrong: K is 0 for patient {ptid}')\n",
    "    except Exception as e:\n",
    "        print(f'Error: something wrong about K for patient {ptid}, Error: {e}')\n",
    "    finally:\n",
    "        Patients_covtype_test.append((ptid, cov_type_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Patients_K_inval_IDrep = pd.merge(inval_set_pyradiomics_ITH[['CaseID']], Patients_K_test, on='CaseID', how='left')\n",
    "Patients_K_inval_IDrep.to_excel('/path/to/Inval_ITH_feature_vector')\n",
    "#cluster_labels_all_test.to_excel('/path/to/Inval_ITH_feature_cluster')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "External test set cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set_pyradiomics_ITH = pd.read_excel('/path/to/Testing_feature_ITH')\n",
    "columns_to_keep = ['CaseID','ID'] + [col for col in testing_set_pyradiomics_ITH.columns if col in significant_features] \n",
    "\n",
    "testing_pyradiomics_ITH = testing_set_pyradiomics_ITH[columns_to_keep].copy() \n",
    "\n",
    "df_numeric_test = testing_pyradiomics_ITH.drop(['ID','CaseID'], axis=1).apply(pd.to_numeric)\n",
    "testing_pyradiomics_cluster_test_ITH = df_numeric_test.reset_index(drop=True)\n",
    "\n",
    "features_to_scale_test_ITH = testing_pyradiomics_cluster_test_ITH.drop(['CaseID','ID'], axis=1)\n",
    "scaled_features_test_ITH  = training_scaler.transform(features_to_scale_test_ITH)\n",
    "\n",
    "scaled_features_test_df = pd.DataFrame(scaled_features_test_ITH, columns=features_to_scale_test_ITH.columns)\n",
    "df_test_standardized = pd.concat([testing_pyradiomics_cluster_test_ITH[['CaseID', 'ID']], scaled_features_test_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Patients_K_exter=  Patients_K[['CaseID'] +[col for col in Patients_K.columns if col in significant_features]].copy()\n",
    "max_K_values = Patients_K_exter.iloc[:, 1:].max()\n",
    "\n",
    "cluster_labels_test_all = df_test_standardized\n",
    "ptid_K0_test = []\n",
    "Patients_K_test = pd.DataFrame()\n",
    "cluster_labels_all_test = pd.DataFrame()\n",
    "ptid = []\n",
    "Patients_covtype_test = []\n",
    "\n",
    "for ptid, group in cluster_labels_test_all.groupby('CaseID'):\n",
    "    try:\n",
    "        analysis_data = group.drop(['CaseID'], axis=1)\n",
    "        K, cov_type_list = assign_K_value2features(analysis_data.drop(['ID'], axis=1), K_num) \n",
    "        K_limited = K\n",
    "\n",
    "        if sum(K_limited) != 0:\n",
    "            cluster_labels_df = cluster_patient_features(analysis_data.drop(['ID'], axis=1), K_limited, cov_type_list)\n",
    "\n",
    "            cluster_labels_df['ID'] = analysis_data['ID'].values  \n",
    "            cluster_labels_df['CaseID'] = ptid\n",
    "\n",
    "            cols = cluster_labels_df.columns.tolist()\n",
    "            cols = ['ID', 'CaseID'] + [col for col in cols if col not in ['ID', 'CaseID']]\n",
    "            cluster_labels_df = cluster_labels_df[cols]\n",
    "            cluster_labels_all_test = pd.concat([cluster_labels_all_test, cluster_labels_df], ignore_index=True, axis=0)\n",
    "\n",
    "            K_new = [ptid] + K_limited  \n",
    "            K_new_df=pd.DataFrame([K_new], columns=['CaseID'] +  list(cluster_labels_validation_all.columns.drop(['ID','CaseID'])))\n",
    "            Patients_K_test = pd.concat([Patients_K_test, K_new_df], ignore_index=True, axis=0)\n",
    "        else:\n",
    "            ptid_K0_test.append(ptid)\n",
    "            print(f'something wrong: K is 0 for patient {ptid}')\n",
    "    except Exception as e:\n",
    "        print(f'Error: something wrong about K for patient {ptid}, Error: {e}')\n",
    "    finally:\n",
    "        Patients_covtype_test.append((ptid, cov_type_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Patients_K_test_IDrep = pd.merge(testing_pyradiomics_ITH[['CaseID']], Patients_K_test, on='CaseID', how='left')\n",
    "Patients_K_test_IDrep.to_excel('/path/to/testing_ITH_feature_vector')\n",
    "#cluster_labels_all_test.to_excel('/path/to/testing_ITH_feature_cluster')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TCIA-TCGA数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TCIA_TCGA_set_pyradiomics_ITH = pd.read_excel('/path/to/TCIA_TCGA_feature_ITH')\n",
    "columns_to_keep = ['CaseID','ID'] + [col for col in TCIA_TCGA_set_pyradiomics_ITH.columns if col in significant_features]\n",
    "\n",
    "TCIA_TCGA_pyradiomics_ITH = TCIA_TCGA_set_pyradiomics_ITH[columns_to_keep].copy()  \n",
    "\n",
    "df_numeric_TCGA = TCIA_TCGA_pyradiomics_ITH.drop(['ID','CaseID'], axis=1).apply(pd.to_numeric)\n",
    "TCIA_TCGA_pyradiomics_cluster_test_ITH = df_numeric_TCGA.reset_index(drop=True)\n",
    "\n",
    "features_to_scale_TCIA_TCGA_ITH = TCIA_TCGA_pyradiomics_cluster_test_ITH.drop(['CaseID','ID'], axis=1)\n",
    "scaled_features_TCIA_TCGA_ITH  = training_scaler.transform(features_to_scale_TCIA_TCGA_ITH)\n",
    "\n",
    "\n",
    "scaled_features_TCIA_TCGA_df = pd.DataFrame(scaled_features_TCIA_TCGA_ITH, columns=features_to_scale_TCIA_TCGA_ITH.columns)\n",
    "df_TCIA_TCGA_standardized = pd.concat([TCIA_TCGA_pyradiomics_cluster_test_ITH[['CaseID', 'ID']], scaled_features_TCIA_TCGA_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels_TCIA_TCGA_all = df_TCIA_TCGA_standardized\n",
    "ptid_K0_TCIA_TCGA = []\n",
    "Patients_K_TCIA_TCGA = pd.DataFrame()\n",
    "cluster_labels_all_TCIA_TCGA = pd.DataFrame()\n",
    "ptid = []\n",
    "Patients_covtype_TCIA_TCGA = []\n",
    "\n",
    "for ptid, group in cluster_labels_TCIA_TCGA_all.groupby('CaseID'):\n",
    "    try:\n",
    "        analysis_data = group.drop(['CaseID'], axis=1)\n",
    "        K, cov_type_list = assign_K_value2features(analysis_data.drop(['ID'], axis=1), K_num) \n",
    "        K_limited = K\n",
    "\n",
    "        if sum(K_limited) != 0:\n",
    "            cluster_labels_df = cluster_patient_features(analysis_data.drop(['ID'], axis=1), K_limited, cov_type_list)\n",
    "\n",
    "            cluster_labels_df['ID'] = analysis_data['ID'].values  \n",
    "            cluster_labels_df['CaseID'] = ptid\n",
    "\n",
    "            cols = cluster_labels_df.columns.tolist()\n",
    "            cols = ['ID', 'CaseID'] + [col for col in cols if col not in ['ID', 'CaseID']]\n",
    "            cluster_labels_df = cluster_labels_df[cols]\n",
    "            cluster_labels_all_TCIA_TCGA = pd.concat([cluster_labels_all_TCIA_TCGA, cluster_labels_df], ignore_index=True, axis=0)\n",
    "\n",
    "            K_new = [ptid] + K_limited   \n",
    "            K_new_df=pd.DataFrame([K_new], columns=['CaseID'] +  list(cluster_labels_validation_all.columns.drop(['ID','CaseID'])))\n",
    "            Patients_K_TCIA_TCGA = pd.concat([Patients_K_TCIA_TCGA, K_new_df], ignore_index=True, axis=0)\n",
    "        else:\n",
    "            ptid_K0_TCIA_TCGA.append(ptid)\n",
    "            print(f'something wrong: K is 0 for patient {ptid}')\n",
    "    except Exception as e:\n",
    "        print(f'Error: something wrong about K for patient {ptid}, Error: {e}')\n",
    "    finally:\n",
    "        Patients_covtype_test.append((ptid, cov_type_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Patients_K_TCIA_TCGA_IDrep = pd.merge(TCIA_TCGA_pyradiomics_ITH[['CaseID']], Patients_K_TCIA_TCGA, on='CaseID', how='left')\n",
    "Patients_K_TCIA_TCGA_IDrep.to_excel('/path/to/TCIA_TCGA_ITH_feature_vector')\n",
    "# cluster_labels_all_TCIA_TCGA.to_excel('/path/to/TCIA_TCGA_ITH_feature_cluster')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
