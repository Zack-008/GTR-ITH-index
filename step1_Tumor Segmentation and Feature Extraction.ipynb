{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is for sub-volume extraction and radiomics calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import SimpleITK as sitk\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import measure, color\n",
    "import skimage.morphology as morphology\n",
    "\n",
    "from skimage.segmentation import mark_boundaries as mark_boundaries\n",
    "from skimage.segmentation import slic as slic\n",
    "\n",
    "import shutil\n",
    "import openpyxl\n",
    "import nibabel as nib\n",
    "import subprocess\n",
    "import pingouin as pg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "supervoxel分割 SLIC算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervoxel(volume_list,mask_list,n_segment,supervoxel_path,center):\n",
    "    print('Start super voxel processing ...')\n",
    "    if not os.path.exists(supervoxel_path):\n",
    "        os.makedirs(supervoxel_path)      \n",
    "    \n",
    "    if not os.path.exists(os.path.join(supervoxel_path,center)):\n",
    "        os.makedirs(os.path.join(supervoxel_path,center))\n",
    "\n",
    "    failed_cases = []\n",
    "\n",
    "    for volume_path, mask_path in zip(volume_list, mask_list):   \n",
    "        try:  \n",
    "            volume_itk = sitk.ReadImage(volume_path)\n",
    "            img = sitk.GetArrayFromImage(volume_itk)\n",
    "            mask = sitk.GetArrayFromImage(sitk.ReadImage(mask_path))\n",
    "            img_normalized = cv2.normalize(img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "            tmp_mask = morphology.opening(mask, morphology.ball(1)) \n",
    "\n",
    "            slic_mask = slic(img_normalized, n_segment, compactness=10, mask=tmp_mask, start_label=1,\n",
    "                             channel_axis=None)\n",
    "        \n",
    "            mask_itk = sitk.GetImageFromArray(np.uint16(slic_mask))\n",
    "            mask_itk.CopyInformation(volume_itk)\n",
    "\n",
    "            output_name = os.path.join(supervoxel_path,center,center+'_' + os.path.basename(mask_path).split('.nii')[0] + '_SVmask.nii.gz')\n",
    "            sitk.WriteImage(mask_itk, output_name)\n",
    "            print('{} is Done'.format(output_name.split('/')[-1]))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'something wrong, SV computation failed for {os.path.basename(volume_path)}: {e}')\n",
    "            failed_cases.append(os.path.basename(volume_path))\n",
    "\n",
    "    if failed_cases:\n",
    "        df_failed_cases = pd.DataFrame(failed_cases, columns=['Failed Cases'])\n",
    "        df_failed_cases.to_excel(os.path.join(supervoxel_path,'failed_cases.xlsx'), index=False)\n",
    "        print(\"Failed cases have been saved to 'failed_cases.xlsx'.\")\n",
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SV_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SV_split(volume, mask, out_dir):\n",
    "\n",
    "    mask_array = sitk.GetArrayFromImage(sitk.ReadImage(mask))   \n",
    "    _, num = measure.label(mask_array, connectivity=3, return_num=True) \n",
    "\n",
    "\n",
    "    for i in range(1, num + 1):\n",
    "        section_mask = sitk.GetArrayFromImage(sitk.ReadImage(mask))\n",
    "\n",
    "        section_mask[section_mask != i] = 0 \n",
    "        section_mask[section_mask == i] = 1 \n",
    "        svsplit_path = os.path.join(out_dir,'SVmask') \n",
    "        \n",
    "        if not os.path.exists(svsplit_path):  \n",
    "            os.makedirs(svsplit_path)  \n",
    "\n",
    "        section_mask_itk = sitk.GetImageFromArray(section_mask)\n",
    "        section_mask_itk.CopyInformation(sitk.ReadImage(volume))\n",
    "\n",
    "        sitk.WriteImage(section_mask_itk,\n",
    "                os.path.join(svsplit_path, os.path.basename(mask).split('.nii')[0]) + str(i)+'.nii.gz')\n",
    "        \n",
    "        print(f'split {os.path.basename(mask).split(\".nii\")[0]} is Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pyradiomics(input_path, params_path, output_path):\n",
    "    # Define the command\n",
    "    command = ['pyradiomics', input_path, '-p', params_path, '-o', output_path,'-f', 'csv']\n",
    "    # Run the command\n",
    "    subprocess.run(command, shell=True)\n",
    "\n",
    "params_path = \"/path/to/params\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dataset(list_volume, list_mask):  \n",
    "    if len(list_volume) != len(list_mask):\n",
    "        raise ValueError('There exists a mismatch between two datasets.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set User Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/path/to/output_dir\"\n",
    "n_segment = 100\n",
    "center = 'hn'\n",
    "\n",
    "SVS_dir = os.path.join(output_dir,'SV','SVSplit')\n",
    "SVSmask_dir = os.path.join(output_dir,'SV','SVSplit','SVmask')\n",
    "SVwhole_dir = os.path.join(output_dir,'SV','SVWhole')\n",
    "\n",
    "dir_list = [output_dir,SVS_dir,SVSmask_dir,SVwhole_dir]\n",
    "for dir in dir_list:\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyradiomics_input_path = \"/path/to/pyradiomics_input\"\n",
    "\n",
    "df = pd.read_csv(pyradiomics_input_path)\n",
    "\n",
    "volume_list = df['Image'].tolist()\n",
    "mask_list = df['Mask'].tolist()\n",
    "\n",
    "check_dataset(volume_list, mask_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(\"/path/to/output.csv\")  \n",
    "\n",
    "run_pyradiomics(pyradiomics_input_path,params_path,output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation of sub-volume calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervoxel calculation by slic\n",
    "supervoxel(volume_list, mask_list, n_segment, SVwhole_dir, center) \n",
    "print('Supervoxel Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_list = glob.glob(os.path.join(SVwhole_dir,center, '*'))\n",
    "sv_list.sort()\n",
    "\n",
    "volume_list2 = []\n",
    "\n",
    "for sv_path  in sv_list:\n",
    "    new_filename = os.path.join(\"/path/to/save\",'_'.join(os.path.basename(sv_path).split('_')[1:-2])+ \".nii.gz\")\n",
    "    volume_list2.append(new_filename)\n",
    "\n",
    "check_dataset(volume_list2, sv_list)\n",
    "\n",
    "print('Start SV split processing ...')\n",
    "for volume_i, mask_j in zip(volume_list2, sv_list):\n",
    "    SV_split(volume_i, mask_j, SVS_dir)  \n",
    "print('SV split done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_files = glob.glob(os.path.join(SVSmask_dir,'*'))\n",
    "volume_threshold = np.prod([3, 3, 3])\n",
    "\n",
    "filtered_masks = []\n",
    "small_filtered_masks = []  \n",
    "\n",
    "for mask_file in mask_files:\n",
    "    mask = nib.load(mask_file)\n",
    "    mask_data = mask.get_fdata()\n",
    "    mask_volume = np.sum(mask_data > 0)\n",
    "    \n",
    "    if mask_volume > volume_threshold:\n",
    "        filtered_masks.append(mask_file)\n",
    "    else:\n",
    "        small_filtered_masks.append({'Mask File': mask_file, 'Volume': mask_volume})\n",
    "\n",
    "if small_filtered_masks: \n",
    "    df_rejected = pd.DataFrame(small_filtered_masks)\n",
    "    df_rejected.to_excel(os.path.join(output_dir,\"small_masks.xlsx\"), index=False)\n",
    "\n",
    "print(\"Filtered Masks Done\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate case table for radiomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_filtered_files = glob.glob(os.path.join(SVSmask_dir, '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mask_filtered_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = []\n",
    "for file_path in mask_filtered_files:\n",
    "    new_filename =os.path.join(\"/path/to/save\",'_'.join(os.path.basename(file_path).split('_')[1:-2])+ \".nii.gz\")\n",
    "    image_files.append(new_filename)\n",
    "\n",
    "check_dataset(image_files, mask_filtered_files)\n",
    "\n",
    "data = []\n",
    "for img_file, mask_file in zip(image_files, mask_filtered_files):\n",
    "    id = os.path.basename(mask_file).split('.nii')[0]\n",
    "    \n",
    "    data.append([id, img_file, mask_file])\n",
    "\n",
    "df = pd.DataFrame(data, columns=['ID', 'Image', 'Mask'])\n",
    "\n",
    "df.to_csv(os.path.join(output_dir ,'featurelevel_input.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation of radiomics calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = os.path.join(output_dir ,'featurelevel_input.csv')\n",
    "output_path = os.path.join(output_dir ,'featurelevel_output.csv')\n",
    "\n",
    "run_pyradiomics(input_path,params_path,output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_filtered_files = glob.glob(os.path.join(SVwhole_dir,'hn', '*'))\n",
    "image_files = []\n",
    "\n",
    "for file_path in mask_filtered_files:\n",
    "    new_filename =os.path.join(\"/path/to/save\",'_'.join(os.path.basename(file_path).split('_')[3:-2])+ \"_image.nii.gz\")\n",
    "    image_files.append(new_filename)\n",
    "\n",
    "check_dataset(image_files, mask_filtered_files)\n",
    "\n",
    "data = []\n",
    "for img_file, mask_file in zip(image_files, mask_filtered_files):\n",
    "    id = os.path.basename(mask_file).split('.nii')[0]\n",
    "    \n",
    "    data.append([id, img_file, mask_file])\n",
    "\n",
    "df = pd.DataFrame(data, columns=['ID', 'Image', 'Mask'])\n",
    "\n",
    "df.to_csv(os.path.join(output_dir ,'ICC_tumourlevel_input.csv'), index=False)\n",
    "\n",
    "input_path = os.path.join(output_dir ,'ICC_tumourlevel_input.csv')\n",
    "output_path = os.path.join(output_dir ,'ICC_tumourlevel_output.csv')\n",
    "\n",
    "run_pyradiomics(input_path,params_path,output_path)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4c8b98c6a0645d8fa0f65a00904b5a10243a3a33010fbbccb3a261768de0a6f3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mma')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
