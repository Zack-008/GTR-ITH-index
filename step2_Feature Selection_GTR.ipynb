{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pingouin as pg\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from mirp import extract_features\n",
    "from mirp.settings.perturbation_parameters import ImagePerturbationSettingsClass\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intraclass correlation coefficients(ICC) analyses (GTR Level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/path/to/ICC_data')\n",
    "\n",
    "df['reader'] = df['ID'].apply(lambda x: 'r1' if 'ICC_1' in x else 'r2') \n",
    "\n",
    "prefixes_to_keep = ['original_shape_', 'original_firstorder_', 'original_glcm_', 'original_glrlm_', 'original_glszm_', 'original_gldm_', 'original_ngtdm_']\n",
    "\n",
    "columns_to_keep = ['CaseID','reader'] + [col for col in df.columns if any(col.startswith(prefix) for prefix in prefixes_to_keep)]\n",
    "\n",
    "ICC_inter = df[columns_to_keep].copy() \n",
    "ICC_inter['reader'] = ICC_inter['reader'].astype(str)\n",
    "icc_results =  []\n",
    "\n",
    "for column in ICC_inter.columns[2:]:\n",
    "    icc_data = ICC_inter[['CaseID', 'reader', column]].copy()\n",
    "    icc_data = icc_data.pivot(index='CaseID', columns='reader', values=column).reset_index()\n",
    "    icc_data.columns.name = None  \n",
    "    \n",
    "    icc_data_melted = icc_data.melt(id_vars='CaseID', value_vars=['r1', 'r2'], var_name='reader', value_name=column)\n",
    "    icc = pg.intraclass_corr(data=icc_data_melted, targets='CaseID', raters='reader', ratings=column, nan_policy='omit').round(3)\n",
    "    icc['feature'] = column  \n",
    "    icc_results.append(icc)\n",
    "\n",
    "icc_results_df = pd.concat(icc_results, ignore_index=True)\n",
    "icc_results_df.to_csv('/path/to/ICC_result.csv')\n",
    "\n",
    "print('ICC calculation completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icc_filtered_df = icc_results_df[(icc_results_df['Type'] == 'ICC3') & (icc_results_df['ICC'] <= 0.75)]\n",
    "icc_features_remove = icc_filtered_df['feature'].unique()\n",
    "print(f'Removed features number: {len(icc_features_remove)}')\n",
    "print(icc_features_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perturbation  (GTR & ITH Level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_label(row):\n",
    "    if row['image_noise_level'] == 0 and pd.isna(row['image_noise_iteration_id']) and row['image_rotation_angle'] == 0 and row['image_translation_x'] == 0 and row['image_translation_y'] == 0 and row['image_translation_z'] == 0:\n",
    "        return 'r1'\n",
    "    elif row['image_noise_iteration_id'] == 0 and row['image_rotation_angle'] == 0.5 and row['image_translation_x'] == 0.5 and row['image_translation_y'] == 0.5 and row['image_translation_z'] == 0.5:\n",
    "        return 'r2'\n",
    "    elif row['image_noise_iteration_id'] == 1 and row['image_rotation_angle'] == 0.5 and row['image_translation_x'] == 0.5 and row['image_translation_y'] == 0.5 and row['image_translation_z'] == 0.5:\n",
    "        return 'r3'\n",
    "    else:\n",
    "        return 'other' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = '/path/to/config_settings.xml'\n",
    "\n",
    "feature_data = extract_features(\n",
    "    image='/path/to/Perturbation_image',\n",
    "    mask='/path/to/Perturbation_label',\n",
    "    base_discretisation_method='fixed_bin_number',\n",
    "    image_modality='CT',\n",
    "    base_discretisation_bin_width=16.0,\n",
    "    settings=settings  \n",
    ")\n",
    "\n",
    "Perturbation_data = pd.concat(feature_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Perturbation_data['reader'] = Perturbation_data.apply(assign_label, axis=1)\n",
    "\n",
    "prefixes_to_keep = ['stat_', 'ivh_', 'morph_', 'ih_', 'cm_', 'rlm_','szm_', 'dzm_','ngt_','ngl_']\n",
    "columns_to_keep = ['sample_name','reader'] + [col for col in Perturbation_data.columns if any(col.startswith(prefix) for prefix in prefixes_to_keep)]\n",
    "\n",
    "ICC_Pert = Perturbation_data[columns_to_keep].copy() \n",
    "\n",
    "ICC_Pert['sample_name'] = ICC_Pert['sample_name'].astype(str)\n",
    "ICC_Pert['reader'] = ICC_Pert['reader'].astype(str)\n",
    "\n",
    "icc_Pert_results =  []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ICC_Pert.columns[2:]:\n",
    "\n",
    "    icc_data = ICC_Pert[['sample_name', 'reader', column]].copy()\n",
    "    icc_data = icc_data.pivot(index='sample_name', columns='reader', values=column).reset_index()\n",
    "    icc_data.columns.name = None  \n",
    "\n",
    "    icc_data_melted = icc_data.melt(id_vars='sample_name', value_vars=['r1', 'r2', 'r3'], var_name='reader', value_name=column)\n",
    "\n",
    "    icc = pg.intraclass_corr(data=icc_data_melted, targets='sample_name', raters='reader', ratings=column, nan_policy='omit').round(3)\n",
    "    icc['feature'] = column  \n",
    "    icc_Pert_results.append(icc)\n",
    "\n",
    "per_results_df = pd.concat(icc_Pert_results, ignore_index=True)\n",
    "per_results_df.to_csv('/path/to/perturbation_result_GTR.csv')\n",
    "print('Complete!')\n",
    "\n",
    "per_filtered_df = per_results_df[(per_results_df['Type'] == 'ICC3k') & (per_results_df['ICC'] <= 0.75)] \n",
    "pert_features_remove = per_filtered_df['feature'].unique()\n",
    "len(pert_features_remove)\n",
    "# These features need to align with corresponding pyradiomics features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_features = np.unique(np.concatenate((pert_features_remove, icc_features_remove))) \n",
    "Combined_removed_features = pd.DataFrame(removed_features, columns=['removed_Feature'])\n",
    "Combined_removed_features.to_excel('/path/to/Removed_features_GTR', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Dimensionality Reduction--GTR Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_features(df_stand, id_columns):\n",
    "    if isinstance(id_columns, str): \n",
    "        id_columns = [id_columns]\n",
    "    df_stand.reset_index(drop=True, inplace=True)   \n",
    "    features_to_scale = df_stand.drop(columns=id_columns)   \n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(features_to_scale)\n",
    "    \n",
    "    scaled_features_df = pd.DataFrame(scaled_features, columns=features_to_scale.columns)\n",
    "    \n",
    "    id_columns_df = df_stand[id_columns]\n",
    "    \n",
    "    result_df = pd.concat([id_columns_df, scaled_features_df], axis=1)\n",
    "    \n",
    "    return result_df, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_pyradiomics = ('/path/to/training_data')\n",
    "\n",
    "combined_removed_features_GTR = pd.read_excel('/path/to/Removed_features_GTR')\n",
    "prefixes_features_GTR_remove = combined_removed_features_GTR['removed_Feature'].tolist()\n",
    "\n",
    "train_set = training_pyradiomics.drop(columns=prefixes_features_GTR_remove).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson correlation analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCC_inter_standard, training_scaler = standardize_features(train_set,['ID'])\n",
    "\n",
    "corr_matrix = PCC_inter_standard.drop(['ID'], axis=1).corr()  \n",
    "\n",
    "high_corr_var=np.where(corr_matrix>0.75)  \n",
    "\n",
    "to_remove = set()  \n",
    "\n",
    "for var in zip(*high_corr_var):  \n",
    "    if var[0] != var[1] and var[0] not in to_remove: \n",
    "        to_remove.add(var[1]) \n",
    "\n",
    "df_filtered = PCC_inter_standard.drop(columns=PCC_inter_standard.columns[list(to_remove)]) \n",
    "pcc_features_remove = corr_matrix.columns[list(to_remove)]\n",
    "len(pcc_features_remove) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Independent T-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clinical = ('/path/to/clinical_data')\n",
    "df_Ttest = pd.merge(PCC_inter_standard, df_clinical[['ID', 'ORR_RECIST1.1']], on='ID', how='left')\n",
    "\n",
    "columns = list(df_Ttest.columns)\n",
    "columns.remove('ORR_RECIST1.1')\n",
    "columns.remove('ID')\n",
    "columns.insert(1, 'ORR_RECIST1.1')\n",
    "df_Ttest = df_Ttest[columns]\n",
    "\n",
    "columns_to_remove = list(prefixes_features_GTR_remove) + list(pcc_features_remove)\n",
    "df_Ttest = df_Ttest.drop(columns=columns_to_remove) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_0 = df_Ttest[df_Ttest['ORR_RECIST1.1'] == 0]  \n",
    "group_1 = df_Ttest[df_Ttest['ORR_RECIST1.1'] == 1] \n",
    "\n",
    "features = df_Ttest.columns[2:]\n",
    "significant_features = []\n",
    "p_values = []\n",
    "for feature in features:\n",
    "    stat, p_value = ttest_ind(group_0[feature], group_1[feature])\n",
    "    p_values.append(p_value)  \n",
    "    if p_value < 0.05:  \n",
    "        significant_features.append(feature)\n",
    "\n",
    "print(len(significant_features), 'Significant features:', significant_features)\n",
    "p_values_df = pd.DataFrame({'Feature': features, 'P-Value': p_values})\n",
    "print(p_values_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features_GTR = pd.DataFrame(significant_features, columns=['Feature'])\n",
    "final_features_GTR.to_excel('/path/to/final_features_GTR_list', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training set\n",
    "columns_to_keep = ['ID'] + [col for col in df_Ttest.columns if col in set(final_features_GTR['Feature'])]  \n",
    "training_pyradiomics_cluster_test = df_Ttest[columns_to_keep].copy() \n",
    "scaled_train_set, training_scaler = standardize_features(training_pyradiomics_cluster_test,'ID')\n",
    "\n",
    "# # Internal validation set\n",
    "invalset_pyradiomics = ('/path/to/invalset_data')\n",
    "finalfeature_inval_set = invalset_pyradiomics[columns_to_keep].copy() \n",
    "\n",
    "scaled_inval_set  = training_scaler.transform(finalfeature_inval_set.drop(['ID'], axis=1))\n",
    "scaled_inval_set = pd.DataFrame(scaled_inval_set, columns=finalfeature_inval_set.drop(['ID'], axis=1).columns)\n",
    "scaled_inval_set = pd.concat([invalset_pyradiomics['ID'], scaled_inval_set], axis=1)\n",
    "\n",
    "# # External test set\n",
    "test_set_pyradiomics = pd.read_excel('/path/to/testset_data')\n",
    "test_set_temp_for_srandardized= test_set_pyradiomics[columns_to_keep].copy() \n",
    "\n",
    "scaled_test_set  = training_scaler.transform(test_set_temp_for_srandardized.drop(['ID'], axis=1))\n",
    "scaled_test_set = pd.DataFrame(scaled_test_set, columns=test_set_temp_for_srandardized.drop(['ID'], axis=1).columns)\n",
    "scaled_test_set = pd.concat([test_set_pyradiomics['ID'], scaled_test_set], axis=1)\n",
    "\n",
    "# # TCIA--TCGA\n",
    "TCIA_TCGA_pyradiomics = pd.read_excel('/path/to/TCGAset_data')\n",
    "\n",
    "TCIA_TCGA_temp_for_srandardized= TCIA_TCGA_pyradiomics[columns_to_keep].copy() \n",
    "\n",
    "scaled_TCIA_TCGA  = training_scaler.transform(TCIA_TCGA_temp_for_srandardized.drop(['ID'], axis=1))\n",
    "scaled_TCIA_TCGA = pd.DataFrame(scaled_TCIA_TCGA, columns=TCIA_TCGA_temp_for_srandardized.drop(['ID'], axis=1).columns)\n",
    "scaled_TCIA_TCGA = pd.concat([TCIA_TCGA_pyradiomics['ID'], scaled_TCIA_TCGA], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
